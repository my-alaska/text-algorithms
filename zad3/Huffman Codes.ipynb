{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abf93307",
   "metadata": {},
   "source": [
    "# Huffman codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "431a0a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import heappush, heappop\n",
    "from bitarray import bitarray\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d7224a",
   "metadata": {},
   "source": [
    "## Algorithm for generating Huffman's code dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55a6ce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def huffman(letter_counts):\n",
    "    class Node:\n",
    "        def __init__(self, weight, left=None, right=None, letter=None):\n",
    "            self.weight = weight\n",
    "            self.left = left\n",
    "            self.right = right\n",
    "            self.letter = letter\n",
    "\n",
    "        def __gt__(self, other):\n",
    "            return self.weight > other.weight\n",
    "\n",
    "        def __ge__(self, other):\n",
    "            return self.weight >= other.weight\n",
    "\n",
    "    letter_counts.sort(key=lambda l: l[0])\n",
    "    result = []\n",
    "    for letter, weight in letter_counts:\n",
    "        heappush(result, Node(weight, letter=letter))\n",
    "    while len(result) > 1:\n",
    "        element_1 = heappop(result)\n",
    "        element_2 = heappop(result)\n",
    "        heappush(\n",
    "            result, Node(element_1.weight + element_2.weight, element_1, element_2)\n",
    "        )\n",
    "\n",
    "    result_dict = {}\n",
    "\n",
    "    def rec(node, code):\n",
    "        nonlocal result_dict\n",
    "        if node.letter is not None:\n",
    "            result_dict[node.letter] = code\n",
    "        else:\n",
    "            lcode, rcode = code.copy(), code.copy()\n",
    "            lcode.append(0)\n",
    "            rcode.append(1)\n",
    "            rec(node.left, lcode)\n",
    "            rec(node.right, rcode)\n",
    "\n",
    "    empty_code = bitarray()\n",
    "    rec(result[0], empty_code)\n",
    "\n",
    "    return result_dict, result[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b5d5dc",
   "metadata": {},
   "source": [
    "## Algorithm utilising Huffman's code dictionary to encode a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90baa481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(string):\n",
    "    no_letters = {}\n",
    "    for letter in string:\n",
    "        if letter not in no_letters.keys():\n",
    "            no_letters[letter] = 0\n",
    "        no_letters[letter] += 1\n",
    "\n",
    "    letter_counts = list(no_letters.items())\n",
    "    letter_counts.sort(key=lambda l: l[0])\n",
    "\n",
    "    text_info = bitarray()\n",
    "    for letter, weight in letter_counts:\n",
    "        l, w = bitarray(), bitarray()\n",
    "        l.frombytes(letter.encode(\"utf-8\"))\n",
    "        w.frombytes(weight.to_bytes(4, byteorder=\"big\", signed=False))\n",
    "        text_info += l\n",
    "        text_info += w\n",
    "    text_info_length = bitarray()\n",
    "    text_info_length.frombytes(\n",
    "        len(letter_counts).to_bytes(1, byteorder=\"big\", signed=False)\n",
    "    )\n",
    "\n",
    "    result = text_info_length + text_info\n",
    "    huffman_dict, x = huffman(letter_counts)\n",
    "    for letter in string:\n",
    "        result += huffman_dict[letter]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b49205",
   "metadata": {},
   "source": [
    "## Algorithm decoding a file encoded with Huffman's code dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1f7edae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(bit_arr):\n",
    "    n = int.from_bytes(bit_arr[:8], byteorder=\"big\", signed=False)\n",
    "    bit_arr = bit_arr[8:]\n",
    "\n",
    "    letter_counts = []\n",
    "    for i in range(n):\n",
    "        letter = bit_arr[:8].tobytes().decode(\"utf-8\")\n",
    "        bit_arr = bit_arr[8:]\n",
    "        weight = int.from_bytes(bit_arr[:32], byteorder=\"big\", signed=False)\n",
    "        bit_arr = bit_arr[32:]\n",
    "        letter_counts.append([letter, weight])\n",
    "    huffman_dict, root = huffman(letter_counts)\n",
    "    i = 0\n",
    "    result = \"\"\n",
    "    while i != len(bit_arr):\n",
    "        node = root\n",
    "        while node.letter is None:\n",
    "            if bit_arr[i] == 1:\n",
    "                node = node.right\n",
    "            else:\n",
    "                node = node.left\n",
    "            i += 1\n",
    "        result += node.letter\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4036a2f2",
   "metadata": {},
   "source": [
    "## Functions and classes for adaptive Huffman encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6e79f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, weight=0, left=None, right=None, letter=None, parent=None):\n",
    "        self.weight = weight\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.letter = letter\n",
    "        self.parent = parent\n",
    "\n",
    "    def __gt__(self, other):\n",
    "        return self.weight > other.weight\n",
    "\n",
    "    def __ge__(self, other):\n",
    "        return self.weight >= other.weight\n",
    "\n",
    "\n",
    "def create_dict(root):\n",
    "    result_dict = {}\n",
    "\n",
    "    def rec(node, code):\n",
    "        nonlocal result_dict\n",
    "        if node.left is None and node.right is None:\n",
    "            result_dict[node.letter] = code\n",
    "        else:\n",
    "            lcode, rcode = code.copy(), code.copy()\n",
    "            lcode.append(0)\n",
    "            rcode.append(1)\n",
    "            rec(node.left, lcode)\n",
    "            rec(node.right, rcode)\n",
    "\n",
    "    empty_code = bitarray()\n",
    "    rec(root, empty_code)\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "def swap(node1, node2):\n",
    "    if node1.parent == node2.parent:\n",
    "        parent = node1.parent\n",
    "        parent.left, parent.right = parent.right, parent.left\n",
    "        node1.parent, node2.parent = node2.parent, node1.parent\n",
    "    else:\n",
    "        if node1.parent.left == node1:\n",
    "            node1.parent.left = node2\n",
    "        else:\n",
    "            node1.parent.right = node2\n",
    "        if node2.parent.left == node2:\n",
    "            node2.parent.left = node1\n",
    "        else:\n",
    "            node2.parent.right = node1\n",
    "        node1.parent, node2.parent = node2.parent, node1.parent\n",
    "\n",
    "\n",
    "def increment(node):\n",
    "    update = False\n",
    "    while node is not None:\n",
    "        node.weight += 1\n",
    "        if (\n",
    "            node.left is not None\n",
    "            and node.right is not None\n",
    "            and node.left.weight > node.right.weight\n",
    "        ):\n",
    "            swap(node.left, node.right)\n",
    "            update = True\n",
    "        node = node.parent\n",
    "    return update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ffd019",
   "metadata": {},
   "source": [
    "## adaptive Huffman encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4dce328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_encode(string):\n",
    "    nodes = {\"#\": Node(weight=0, letter=\"#\")}\n",
    "    root = nodes[\"#\"]\n",
    "    dict_now = create_dict(root)\n",
    "    result = bitarray()\n",
    "    for letter in string:\n",
    "        if letter in nodes.keys():\n",
    "            node = nodes[letter]\n",
    "\n",
    "            result += dict_now[letter]\n",
    "\n",
    "            update = increment(node)\n",
    "            if update:\n",
    "                dict_now = create_dict(root)\n",
    "        else:\n",
    "            updated_node = nodes[\"#\"]\n",
    "\n",
    "            result += dict_now[\"#\"]\n",
    "            l = bitarray()\n",
    "            l.frombytes(letter.encode(\"utf-8\"))\n",
    "            result += l\n",
    "\n",
    "            node = Node(weight=1, letter=letter, parent=updated_node)\n",
    "            nodes[letter] = node\n",
    "            del nodes[\"#\"]\n",
    "            zero_node = Node(weight=0, letter=\"#\", parent=updated_node)\n",
    "            updated_node.left, updated_node.right = zero_node, node\n",
    "            nodes[\"#\"] = zero_node\n",
    "\n",
    "            increment(updated_node)\n",
    "            dict_now = create_dict(root)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e146a82a",
   "metadata": {},
   "source": [
    "## adaptive Huffman decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8e7c8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_decode(bit_arr):\n",
    "    nodes = {\"#\": Node(weight=0, letter=\"#\")}\n",
    "    root = nodes[\"#\"]\n",
    "\n",
    "    i = 0\n",
    "    result = \"\"\n",
    "    while i != len(bit_arr):\n",
    "        node = root\n",
    "        while node.left is not None and node.right is not None:\n",
    "            if bit_arr[i] == 1:\n",
    "                node = node.right\n",
    "            else:\n",
    "                node = node.left\n",
    "            i += 1\n",
    "\n",
    "        if node.letter != \"#\":\n",
    "            letter = node.letter\n",
    "            result += letter\n",
    "            node = nodes[letter]\n",
    "            update = increment(node)\n",
    "\n",
    "        else:\n",
    "\n",
    "            letter = bit_arr[i : i + 8].tobytes().decode()\n",
    "            i += 8\n",
    "            result += letter\n",
    "\n",
    "            updated_node = nodes[\"#\"]\n",
    "            node = Node(weight=1, letter=letter, parent=updated_node)\n",
    "            nodes[letter] = node\n",
    "            del nodes[\"#\"]\n",
    "            zero_node = Node(weight=0, letter=\"#\", parent=updated_node)\n",
    "            updated_node.left, updated_node.right = zero_node, node\n",
    "            nodes[\"#\"] = zero_node\n",
    "\n",
    "            increment(updated_node)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d8bfa12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trudne sysopy w tym tygodniu bardzo\n"
     ]
    }
   ],
   "source": [
    "print(decode(encode(\"Trudne sysopy w tym tygodniu bardzo\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c22389bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utrudzony jestem przez studia bardzo oj bardzo\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    adaptive_decode(adaptive_encode(\"Utrudzony jestem przez studia bardzo oj bardzo\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b8ad8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(file_name):\n",
    "    file = open(file_name, \"r\")\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "\n",
    "    t1 = time.perf_counter()\n",
    "    encoded = encode(text)\n",
    "    t2 = time.perf_counter()\n",
    "    decoded = decode(encoded)\n",
    "    t3 = time.perf_counter()\n",
    "    file2 = open(\"tmp.rrr\", \"wb\")\n",
    "    encoded.tofile(file2)\n",
    "    file2.close()\n",
    "    size1 = os.path.getsize(file_name)\n",
    "    size2 = os.path.getsize(\"tmp.rrr\")\n",
    "    os.remove(\"tmp.rrr\")\n",
    "    print(round(100 * size2 / size1, 2), \"%\", sep=\"\")\n",
    "    print(\"encoding\", f\"{t2-t1:.6}\", \"s\")\n",
    "    print(\"decoding\", f\"{t3-t2:.6}\", \"s\")\n",
    "\n",
    "    t1 = time.perf_counter()\n",
    "    encoded = adaptive_encode(text)\n",
    "    t2 = time.perf_counter()\n",
    "    decoded = adaptive_decode(encoded)\n",
    "    t3 = time.perf_counter()\n",
    "    file2 = open(\"tmp.rrr\", \"wb\")\n",
    "    encoded.tofile(file2)\n",
    "    file2.close()\n",
    "    size1 = os.path.getsize(file_name)\n",
    "    size2 = os.path.getsize(\"tmp.rrr\")\n",
    "    os.remove(\"tmp.rrr\")\n",
    "    print(round(100 * size2 / size1, 2), \"%\", sep=\"\")\n",
    "    print(\"adaptive encoding\", f\"{t2-t1:.6}\", \"s\")\n",
    "    print(\"adaptive decoding\", f\"{t3-t2:.6}\", \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "050ee43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.68%\n",
      "encoding 0.0006396 s\n",
      "decoding 0.0015138 s\n",
      "319.53%\n",
      "adaptive encoding 0.0112388 s\n",
      "adaptive decoding 0.01936 s\n"
     ]
    }
   ],
   "source": [
    "test(\"1kb.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c39ab206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.38%\n",
      "encoding 0.0031182 s\n",
      "decoding 0.0129767 s\n",
      "330.24%\n",
      "adaptive encoding 0.103127 s\n",
      "adaptive decoding 0.163649 s\n"
     ]
    }
   ],
   "source": [
    "test(\"10kb.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9dd32a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.29%\n",
      "encoding 0.0312813 s\n",
      "decoding 0.121605 s\n",
      "330.75%\n",
      "adaptive encoding 1.00544 s\n",
      "adaptive decoding 1.7347 s\n"
     ]
    }
   ],
   "source": [
    "test(\"100kb.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfe89ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.12%\n",
      "encoding 0.332013 s\n",
      "decoding 1.35124 s\n",
      "331.3%\n",
      "adaptive encoding 10.8308 s\n",
      "adaptive decoding 17.0933 s\n"
     ]
    }
   ],
   "source": [
    "test(\"1mb.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf6dd5f",
   "metadata": {},
   "source": [
    "The results for adaptive algorithm are terrible. Why? The answer is simple. We're not using vitters algorithm that balances the tree. Instead we use the regular adaptive algorithm and size of a tree becomes linear. Since letters are randomly generated there's aproximately equal number of nodes encoded by |A| bits and by 1 bit (where |A| is a size of alphabet) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f48cec",
   "metadata": {},
   "source": [
    "### Out of pure curiousity I decided to see if a text similar to real language shows different behaviour than random characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cea41997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.45%\n",
      "encoding 0.0279723 s\n",
      "decoding 0.0980931 s\n",
      "129.01%\n",
      "adaptive encoding 0.408733 s\n",
      "adaptive decoding 0.627759 s\n"
     ]
    }
   ],
   "source": [
    "test(\"100kb_lorem_ipsum.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8ea14d",
   "metadata": {},
   "source": [
    "Of course it does. The difference of 20 percentage points is astonishing. Objects created by humans follow rules like zipf's law or 80-20 rule or many other constraints. Randomly generated characters don't have that \"human\" property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c90a791",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
