{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abf93307",
   "metadata": {},
   "source": [
    "# Huffman codes"
   ]
  },
  {
   "cell_type": "code",
   "id": "431a0a84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T16:11:56.237153Z",
     "start_time": "2025-04-09T16:11:56.234078Z"
    }
   },
   "source": [
    "from heapq import heappush, heappop\n",
    "from bitarray import bitarray\n",
    "import time\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "56d7224a",
   "metadata": {},
   "source": [
    "## Algorithm for generating Huffman's code dictionary"
   ]
  },
  {
   "cell_type": "code",
   "id": "55a6ce89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T16:20:15.075170Z",
     "start_time": "2025-04-09T16:20:15.069838Z"
    }
   },
   "source": [
    "def huffman(letter_counts):\n",
    "    # Define a Node class to store each tree element\n",
    "    class Node:\n",
    "        def __init__(self, weight, left=None, right=None, letter=None):\n",
    "            self.weight = weight    # Total frequency or weight\n",
    "            self.left = left        # Left child (Node)\n",
    "            self.right = right      # Right child (Node)\n",
    "            self.letter = letter    # Character/letter if this is a leaf node\n",
    "\n",
    "        # Define comparison operators so the heapq module can sort Nodes\n",
    "        def __lt__(self, other):  # < operator for heapq to work properly\n",
    "            return self.weight < other.weight\n",
    "\n",
    "        def __gt__(self, other):  # Optional, for completeness\n",
    "            return self.weight > other.weight\n",
    "\n",
    "        def __ge__(self, other):  # Optional, not needed by heapq\n",
    "            return self.weight >= other.weight\n",
    "\n",
    "    # Initialize a heap with leaf nodes\n",
    "    result = []\n",
    "    for letter, weight in letter_counts:\n",
    "        heappush(result, Node(weight, letter=letter))\n",
    "\n",
    "    # Build the Huffman tree by combining the two lowest-weight nodes\n",
    "    while len(result) > 1:\n",
    "        element_1 = heappop(result)\n",
    "        element_2 = heappop(result)\n",
    "        # Create a new internal node with combined weight and push it back\n",
    "        heappush(result, Node(element_1.weight + element_2.weight, element_1, element_2))\n",
    "\n",
    "    result_dict = {}\n",
    "\n",
    "    # Recursive function to traverse the tree and assign bit codes\n",
    "    def rec(node, code):\n",
    "        nonlocal result_dict\n",
    "        if node.letter is not None:\n",
    "            # Leaf node: assign the accumulated code\n",
    "            result_dict[node.letter] = code\n",
    "            return\n",
    "        # Internal node: recurse left with 0, right with 1\n",
    "        lcode = code.copy()\n",
    "        rcode = code.copy()\n",
    "        lcode.append(0)\n",
    "        rcode.append(1)\n",
    "        rec(node.left, lcode)\n",
    "        rec(node.right, rcode)\n",
    "\n",
    "    # Start recursive traversal from the root of the Huffman tree\n",
    "    empty_code = bitarray()\n",
    "    rec(result[0], empty_code)\n",
    "\n",
    "    return result_dict, result[0]"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "id": "27b5d5dc",
   "metadata": {},
   "source": [
    "## Algorithm utilising Huffman's code dictionary to encode a file"
   ]
  },
  {
   "cell_type": "code",
   "id": "90baa481",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T16:20:15.641178Z",
     "start_time": "2025-04-09T16:20:15.637179Z"
    }
   },
   "source": [
    "def encode(string):\n",
    "    # Count the frequency of each character in the string\n",
    "    no_letters = {}\n",
    "    for letter in string:\n",
    "        if letter not in no_letters.keys():\n",
    "            no_letters[letter] = 0\n",
    "        no_letters[letter] += 1\n",
    "\n",
    "    # Create a sorted list of (letter, count) pairs\n",
    "    letter_counts = list(no_letters.items())\n",
    "    letter_counts.sort(key=lambda l: l[0])  # Sorting by letter for consistency\n",
    "\n",
    "    # Encode the frequency table into bits\n",
    "    text_info = bitarray()\n",
    "    for letter, weight in letter_counts:\n",
    "        l, w = bitarray(), bitarray()\n",
    "        l.frombytes(letter.encode(\"utf-8\"))  # Encode the letter as 1 byte\n",
    "        w.frombytes(weight.to_bytes(4, byteorder=\"big\", signed=False))  # 4-byte weight\n",
    "        text_info += l + w  # Append letter and weight\n",
    "\n",
    "    # Encode the number of entries in the frequency table (1 byte)\n",
    "    text_info_length = bitarray()\n",
    "    text_info_length.frombytes(\n",
    "        len(letter_counts).to_bytes(1, byteorder=\"big\", signed=False)\n",
    "    )\n",
    "\n",
    "    # Combine header and frequency data\n",
    "    result = text_info_length + text_info\n",
    "\n",
    "    # Generate Huffman dictionary from letter frequencies\n",
    "    huffman_dict, _ = huffman(letter_counts)\n",
    "\n",
    "    # Encode the actual string using the Huffman codes\n",
    "    for letter in string:\n",
    "        result += huffman_dict[letter]  # Append Huffman bit sequence for each letter\n",
    "\n",
    "    return result  # Final encoded bitarray\n",
    "\n",
    "def decode(bit_arr):\n",
    "    # Read number of unique letters (first 8 bits = 1 byte)\n",
    "    n = int.from_bytes(bit_arr[:8], byteorder=\"big\", signed=False)\n",
    "    bit_arr = bit_arr[8:]  # Remove the byte we just read\n",
    "\n",
    "    # Reconstruct the frequency table\n",
    "    letter_counts = []\n",
    "    for i in range(n):\n",
    "        # Each letter is 8 bits (1 byte UTF-8)\n",
    "        letter = bit_arr[:8].tobytes().decode(\"utf-8\")\n",
    "        bit_arr = bit_arr[8:]\n",
    "\n",
    "        # Each weight is 32 bits (4 bytes)\n",
    "        weight = int.from_bytes(bit_arr[:32], byteorder=\"big\", signed=False)\n",
    "        bit_arr = bit_arr[32:]\n",
    "\n",
    "        letter_counts.append([letter, weight])\n",
    "\n",
    "    # Rebuild the Huffman tree using the frequencies\n",
    "    huffman_dict, root = huffman(letter_counts)\n",
    "\n",
    "    # Decode the remaining bits using the Huffman tree\n",
    "    i = 0\n",
    "    result = \"\"\n",
    "    while i < len(bit_arr):\n",
    "        node = root\n",
    "        # Traverse the tree until a leaf node is found\n",
    "        while node.letter is None:\n",
    "            if bit_arr[i] == 1:\n",
    "                node = node.right\n",
    "            else:\n",
    "                node = node.left\n",
    "            i += 1\n",
    "        result += node.letter  # Append the decoded character\n",
    "\n",
    "    return result  # Final decoded string"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "id": "b3b49205",
   "metadata": {},
   "source": [
    "## Algorithm decoding a file encoded with Huffman's code dictionary"
   ]
  },
  {
   "cell_type": "code",
   "id": "e1f7edae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T16:20:16.061552Z",
     "start_time": "2025-04-09T16:20:16.056543Z"
    }
   },
   "source": [
    "def decode(bit_arr):\n",
    "    n = int.from_bytes(bit_arr[:8], byteorder=\"big\", signed=False)\n",
    "    bit_arr = bit_arr[8:]\n",
    "\n",
    "    letter_counts = []\n",
    "    for i in range(n):\n",
    "        letter = bit_arr[:8].tobytes().decode(\"utf-8\")\n",
    "        bit_arr = bit_arr[8:]\n",
    "        weight = int.from_bytes(bit_arr[:32], byteorder=\"big\", signed=False)\n",
    "        bit_arr = bit_arr[32:]\n",
    "        letter_counts.append([letter, weight])\n",
    "    huffman_dict, root = huffman(letter_counts)\n",
    "    i = 0\n",
    "    result = \"\"\n",
    "    while i != len(bit_arr):\n",
    "        node = root\n",
    "        while node.letter is None:\n",
    "            if bit_arr[i] == 1:\n",
    "                node = node.right\n",
    "            else:\n",
    "                node = node.left\n",
    "            i += 1\n",
    "        result += node.letter\n",
    "    return result"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "id": "4036a2f2",
   "metadata": {},
   "source": [
    "## Functions and classes for adaptive Huffman encoding"
   ]
  },
  {
   "cell_type": "code",
   "id": "e6e79f81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T16:20:16.481842Z",
     "start_time": "2025-04-09T16:20:16.473687Z"
    }
   },
   "source": [
    "class Node:\n",
    "    def __init__(self, weight=0, left=None, right=None, letter=None, parent=None):\n",
    "        self.weight = weight\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.letter = letter\n",
    "        self.parent = parent\n",
    "\n",
    "    def __gt__(self, other):\n",
    "        return self.weight > other.weight\n",
    "\n",
    "    def __ge__(self, other):\n",
    "        return self.weight >= other.weight\n",
    "\n",
    "\n",
    "def create_dict(root):\n",
    "    result_dict = {}\n",
    "\n",
    "    def rec(node, code):\n",
    "        nonlocal result_dict\n",
    "        if node.left is None and node.right is None:\n",
    "            result_dict[node.letter] = code\n",
    "        else:\n",
    "            lcode, rcode = code.copy(), code.copy()\n",
    "            lcode.append(0)\n",
    "            rcode.append(1)\n",
    "            rec(node.left, lcode)\n",
    "            rec(node.right, rcode)\n",
    "\n",
    "    empty_code = bitarray()\n",
    "    rec(root, empty_code)\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "def swap(node1, node2):\n",
    "    if node1.parent == node2.parent:\n",
    "        parent = node1.parent\n",
    "        parent.left, parent.right = parent.right, parent.left\n",
    "        node1.parent, node2.parent = node2.parent, node1.parent\n",
    "    else:\n",
    "        if node1.parent.left == node1:\n",
    "            node1.parent.left = node2\n",
    "        else:\n",
    "            node1.parent.right = node2\n",
    "        if node2.parent.left == node2:\n",
    "            node2.parent.left = node1\n",
    "        else:\n",
    "            node2.parent.right = node1\n",
    "        node1.parent, node2.parent = node2.parent, node1.parent\n",
    "\n",
    "\n",
    "def increment(node):\n",
    "    update = False\n",
    "    while node is not None:\n",
    "        node.weight += 1\n",
    "        if (\n",
    "            node.left is not None\n",
    "            and node.right is not None\n",
    "            and node.left.weight > node.right.weight\n",
    "        ):\n",
    "            swap(node.left, node.right)\n",
    "            update = True\n",
    "        node = node.parent\n",
    "    return update"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "id": "e1ffd019",
   "metadata": {},
   "source": [
    "## adaptive Huffman encoding"
   ]
  },
  {
   "cell_type": "code",
   "id": "c4dce328",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T16:20:16.897973Z",
     "start_time": "2025-04-09T16:20:16.892973Z"
    }
   },
   "source": [
    "def adaptive_encode(string):\n",
    "    nodes = {\"#\": Node(weight=0, letter=\"#\")}\n",
    "    root = nodes[\"#\"]\n",
    "    dict_now = create_dict(root)\n",
    "    result = bitarray()\n",
    "    for letter in string:\n",
    "        if letter in nodes.keys():\n",
    "            node = nodes[letter]\n",
    "\n",
    "            result += dict_now[letter]\n",
    "\n",
    "            update = increment(node)\n",
    "            if update:\n",
    "                dict_now = create_dict(root)\n",
    "        else:\n",
    "            updated_node = nodes[\"#\"]\n",
    "\n",
    "            result += dict_now[\"#\"]\n",
    "            l = bitarray()\n",
    "            l.frombytes(letter.encode(\"utf-8\"))\n",
    "            result += l\n",
    "\n",
    "            node = Node(weight=1, letter=letter, parent=updated_node)\n",
    "            nodes[letter] = node\n",
    "            del nodes[\"#\"]\n",
    "            zero_node = Node(weight=0, letter=\"#\", parent=updated_node)\n",
    "            updated_node.left, updated_node.right = zero_node, node\n",
    "            nodes[\"#\"] = zero_node\n",
    "\n",
    "            increment(updated_node)\n",
    "            dict_now = create_dict(root)\n",
    "    return result"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "id": "e146a82a",
   "metadata": {},
   "source": [
    "## adaptive Huffman decoding"
   ]
  },
  {
   "cell_type": "code",
   "id": "c8e7c8f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T16:20:17.747574Z",
     "start_time": "2025-04-09T16:20:17.743629Z"
    }
   },
   "source": [
    "def adaptive_decode(bit_arr):\n",
    "    nodes = {\"#\": Node(weight=0, letter=\"#\")}\n",
    "    root = nodes[\"#\"]\n",
    "\n",
    "    i = 0\n",
    "    result = \"\"\n",
    "    while i != len(bit_arr):\n",
    "        node = root\n",
    "        while node.left is not None and node.right is not None:\n",
    "            if bit_arr[i] == 1:\n",
    "                node = node.right\n",
    "            else:\n",
    "                node = node.left\n",
    "            i += 1\n",
    "\n",
    "        if node.letter != \"#\":\n",
    "            letter = node.letter\n",
    "            result += letter\n",
    "            node = nodes[letter]\n",
    "            update = increment(node)\n",
    "\n",
    "        else:\n",
    "\n",
    "            letter = bit_arr[i : i + 8].tobytes().decode()\n",
    "            i += 8\n",
    "            result += letter\n",
    "\n",
    "            updated_node = nodes[\"#\"]\n",
    "            node = Node(weight=1, letter=letter, parent=updated_node)\n",
    "            nodes[letter] = node\n",
    "            del nodes[\"#\"]\n",
    "            zero_node = Node(weight=0, letter=\"#\", parent=updated_node)\n",
    "            updated_node.left, updated_node.right = zero_node, node\n",
    "            nodes[\"#\"] = zero_node\n",
    "\n",
    "            increment(updated_node)\n",
    "\n",
    "    return result"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "3d8bfa12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T16:20:18.168016Z",
     "start_time": "2025-04-09T16:20:18.164756Z"
    }
   },
   "source": [
    "print(decode(encode(\"Trudne sysopy w tym tygodniu bardzo\")))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trudne sysopy w tym tygodniu bardzo\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "id": "c22389bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T16:20:18.870457Z",
     "start_time": "2025-04-09T16:20:18.866754Z"
    }
   },
   "source": [
    "print(\n",
    "    adaptive_decode(adaptive_encode(\"Utrudzony jestem przez studia bardzo oj bardzo\"))\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utrudzony jestem przez studia bardzo oj bardzo\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "3b8ad8a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T16:23:34.721848Z",
     "start_time": "2025-04-09T16:23:34.717624Z"
    }
   },
   "source": [
    "def test(file_name):\n",
    "    file = open(file_name, \"r\")\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "\n",
    "    t1 = time.perf_counter()\n",
    "    encoded = encode(text)\n",
    "    t2 = time.perf_counter()\n",
    "    decoded = decode(encoded)\n",
    "    t3 = time.perf_counter()\n",
    "    file2 = open(\"tmp.rrr\", \"wb\")\n",
    "    encoded.tofile(file2)\n",
    "    file2.close()\n",
    "    size1 = os.path.getsize(file_name)\n",
    "    size2 = os.path.getsize(\"tmp.rrr\")\n",
    "    os.remove(\"tmp.rrr\")\n",
    "    print(round(100 * size2 / size1, 2), \"%\", sep=\"\")\n",
    "    print(\"encoding\", f\"{t2-t1:.6}\", \"s\")\n",
    "    print(\"decoding\", f\"{t3-t2:.6}\", \"s\")\n",
    "\n",
    "    t1 = time.perf_counter()\n",
    "    encoded = adaptive_encode(text)\n",
    "    t2 = time.perf_counter()\n",
    "    decoded = adaptive_decode(encoded)\n",
    "    t3 = time.perf_counter()\n",
    "    file2 = open(\"tmp.rrr\", \"wb\")\n",
    "    encoded.tofile(file2)\n",
    "    file2.close()\n",
    "    size1 = os.path.getsize(file_name)\n",
    "    size2 = os.path.getsize(\"tmp.rrr\")\n",
    "    os.remove(\"tmp.rrr\")\n",
    "    print(round(100 * size2 / size1, 2), \"%\", sep=\"\")\n",
    "    print(\"adaptive encoding\", f\"{t2-t1:.6}\", \"s\")\n",
    "    print(\"adaptive decoding\", f\"{t3-t2:.6}\", \"s\")"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "id": "050ee43e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T16:23:35.191776Z",
     "start_time": "2025-04-09T16:23:35.167234Z"
    }
   },
   "source": [
    "test(\"1kb.txt\")"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '1kb.txt'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[38]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mtest\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m1kb.txt\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[37]\u001B[39m\u001B[32m, line 2\u001B[39m, in \u001B[36mtest\u001B[39m\u001B[34m(file_name)\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mtest\u001B[39m(file_name):\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m     file = \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfile_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mr\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      3\u001B[39m     text = file.read()\n\u001B[32m      4\u001B[39m     file.close()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\zajecia\\text-algorithms\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:325\u001B[39m, in \u001B[36m_modified_open\u001B[39m\u001B[34m(file, *args, **kwargs)\u001B[39m\n\u001B[32m    318\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[32m0\u001B[39m, \u001B[32m1\u001B[39m, \u001B[32m2\u001B[39m}:\n\u001B[32m    319\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    320\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mIPython won\u001B[39m\u001B[33m'\u001B[39m\u001B[33mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m by default \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    321\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    322\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33myou can use builtins\u001B[39m\u001B[33m'\u001B[39m\u001B[33m open.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    323\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m325\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: '1kb.txt'"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "id": "c39ab206",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T16:23:36.131508Z",
     "start_time": "2025-04-09T16:23:36.101689Z"
    }
   },
   "source": [
    "test(\"10kb.txt\")"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '10kb.txt'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[39]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mtest\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m10kb.txt\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[37]\u001B[39m\u001B[32m, line 2\u001B[39m, in \u001B[36mtest\u001B[39m\u001B[34m(file_name)\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mtest\u001B[39m(file_name):\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m     file = \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfile_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mr\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      3\u001B[39m     text = file.read()\n\u001B[32m      4\u001B[39m     file.close()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\zajecia\\text-algorithms\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:325\u001B[39m, in \u001B[36m_modified_open\u001B[39m\u001B[34m(file, *args, **kwargs)\u001B[39m\n\u001B[32m    318\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[32m0\u001B[39m, \u001B[32m1\u001B[39m, \u001B[32m2\u001B[39m}:\n\u001B[32m    319\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    320\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mIPython won\u001B[39m\u001B[33m'\u001B[39m\u001B[33mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m by default \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    321\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    322\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33myou can use builtins\u001B[39m\u001B[33m'\u001B[39m\u001B[33m open.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    323\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m325\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: '10kb.txt'"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9dd32a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.29%\n",
      "encoding 0.0312813 s\n",
      "decoding 0.121605 s\n",
      "330.75%\n",
      "adaptive encoding 1.00544 s\n",
      "adaptive decoding 1.7347 s\n"
     ]
    }
   ],
   "source": [
    "test(\"100kb.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfe89ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.12%\n",
      "encoding 0.332013 s\n",
      "decoding 1.35124 s\n",
      "331.3%\n",
      "adaptive encoding 10.8308 s\n",
      "adaptive decoding 17.0933 s\n"
     ]
    }
   ],
   "source": [
    "test(\"1mb.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf6dd5f",
   "metadata": {},
   "source": [
    "The results for adaptive algorithm are terrible. Why? The answer is simple. We're not using vitters algorithm that balances the tree. Instead we use the regular adaptive algorithm and size of a tree becomes linear. Since letters are randomly generated there's aproximately equal number of nodes encoded by |A| bits and by 1 bit (where |A| is a size of alphabet) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f48cec",
   "metadata": {},
   "source": [
    "### Out of pure curiousity I decided to see if a text similar to real language shows different behaviour than random characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cea41997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.45%\n",
      "encoding 0.0279723 s\n",
      "decoding 0.0980931 s\n",
      "129.01%\n",
      "adaptive encoding 0.408733 s\n",
      "adaptive decoding 0.627759 s\n"
     ]
    }
   ],
   "source": [
    "test(\"100kb_lorem_ipsum.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8ea14d",
   "metadata": {},
   "source": [
    "Of course it does. The difference of 20 percentage points is astonishing. Objects created by humans follow rules like zipf's law or 80-20 rule or many other constraints. Randomly generated characters don't have that \"human\" property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c90a791",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
